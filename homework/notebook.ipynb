{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Empaquetado del entrenamiento del modelo\n",
    "#\n",
    "def train_estimator(alpha=0.5, l1_ratio=0.5, verbose=1):\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    estimator = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=12345)\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(estimator, \":\", sep=\"\")\n",
    "        print(f\"  MSE: {mse}\")\n",
    "        print(f\"  MAE: {mae}\")\n",
    "        print(f\"  R2: {r2}\")\n",
    "\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        saved_estimator = None\n",
    "    else:\n",
    "        with open(\"estimator.pickle\", \"rb\") as file:\n",
    "            saved_estimator = pickle.load(file)\n",
    "\n",
    "    if saved_estimator is None or estimator.score(\n",
    "        x_test, y_test\n",
    "    ) > saved_estimator.score(x_test, y_test):\n",
    "        with open(\"estimator.pickle\", \"wb\") as file:\n",
    "            pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cda8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.5, random_state=12345):\n",
      "  MSE: 0.5294843132862007\n",
      "  MAE: 0.5894666734018875\n",
      "  R2: 0.13368827268570616\n"
     ]
    }
   ],
   "source": [
    "train_estimator(0.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1956af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.2, l1_ratio=0.2, random_state=12345):\n",
      "  MSE: 0.4386911951894716\n",
      "  MAE: 0.5236106762028768\n",
      "  R2: 0.2822387414965033\n"
     ]
    }
   ],
   "source": [
    "train_estimator(0.2,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c71e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.3398286 , 5.4181238 , 5.41836123, ..., 5.77802097, 5.5401108 ,\n",
       "       5.71068002], shape=(1599,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Uso del modelo en productivo\n",
    "#\n",
    "def use_estimator():\n",
    "\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    y_pred = estimator.predict(x)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "use_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5026e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Carga de datos\n",
    "#\n",
    "def load_data():\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38639280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Particionamiento de datos\n",
    "#\n",
    "def make_train_test_split(x, y):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=0,\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897c0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cálculo de metricas de evaluación\n",
    "#\n",
    "def eval_metrics(y_true, y_pred):\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9a59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Almacenamiento del modelo\n",
    "#\n",
    "def save_best_estimator(estimator):\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    with open(\"estimator.pickle\", \"wb\") as file:\n",
    "        pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c85bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Carga del modelo\n",
    "#\n",
    "def load_best_estimator():\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        return None\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c6fbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Entrenamiento\n",
    "#\n",
    "def train_estimator(alpha=0.5, l1_ratio=0.5, verbose=1):\n",
    "\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "    estimator = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=12345)\n",
    "    estimator.fit(x_train, y_train)\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    if verbose > 0:\n",
    "        report(estimator, mse, mae, r2)\n",
    "\n",
    "    best_estimator = load_best_estimator()\n",
    "    if best_estimator is None or estimator.score(x_test, y_test) > best_estimator.score(\n",
    "        x_test, y_test\n",
    "    ):\n",
    "        best_estimator = estimator\n",
    "\n",
    "    save_best_estimator(best_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f22426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_estimator\u001b[39m\u001b[34m(alpha, l1_ratio, verbose)\u001b[39m\n\u001b[32m     12\u001b[39m mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mreport\u001b[49m(estimator, mse, mae, r2)\n\u001b[32m     16\u001b[39m best_estimator = load_best_estimator()\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m estimator.score(x_test, y_test) > best_estimator.score(\n\u001b[32m     18\u001b[39m     x_test, y_test\n\u001b[32m     19\u001b[39m ):\n",
      "\u001b[31mNameError\u001b[39m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "train_estimator(0.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f609695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator(0.2, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c19ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator(0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cb427",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator(0.1, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator(0.3, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_estimator():\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "    estimator = load_best_estimator()\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    report(estimator, mse, mae, r2)\n",
    "\n",
    "\n",
    "#\n",
    "# Debe coincidir con el mejor modelo encontrado en la celdas anteriores\n",
    "#\n",
    "check_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparameters_search(alphas, l1_ratios):\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            train_estimator(alpha=alpha, l1_ratio=l1_ratio, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d340633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(alphas, l1_ratios, n_splits=5, verbose=1):\n",
    "\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Búsqueda de parámetros con validación cruzada\n",
    "    #\n",
    "    estimator = GridSearchCV(\n",
    "        estimator=ElasticNet(\n",
    "            random_state=12345,\n",
    "        ),\n",
    "        param_grid={\n",
    "            \"alpha\": alphas,\n",
    "            \"l1_ratio\": l1_ratios,\n",
    "        },\n",
    "        cv=n_splits,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    estimator = estimator.best_estimator_\n",
    "\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    if verbose > 0:\n",
    "        report(estimator, mse, mae, r2)\n",
    "\n",
    "    best_estimator = load_best_estimator()\n",
    "    if best_estimator is None or estimator.score(x_test, y_test) > best_estimator.score(\n",
    "        x_test, y_test\n",
    "    ):\n",
    "        best_estimator = estimator\n",
    "\n",
    "    save_best_estimator(best_estimator)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
